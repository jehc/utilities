WHAT DOES THIS DO?
------------------
The depth and color output from the Kinect cameras are not calibrated.  It is easy to take a depth map, reproject it to 3D, project it down to the color camera, and query the color.  However, some instances require that you pick a particular pixel in the color image and you would like to know where to reproject that point to 3D which is a more difficult inverse problem since points in space may cause occlusion.  What this code does is take the calibrated Kinect camera pair, unproject all of the points from the depth camera into 3D space as a triangle mesh using the depth intrinsics, set the OpenGL camera to the location of the color camera using the extrinsics, and project the depth to each point onto the color image plane.  This is all done using the GPU so the z-buffer takes care of the occlusion part, bilinear interpolation is done for free, and so on.

Ubuntu 10.10 instructions
-------------------------

OpenCV 2.2 is required.  I'm not experienced with the build available in the Ubuntu repositories so here are some steps that I performed on my own machine to get it working.

> sudo apt-get install cmake
> wget http://downloads.sourceforge.net/project/opencvlibrary/opencv-unix/2.2/OpenCV-2.2.0.tar.bz2?r=http%3A%2F%2Fsourceforge.net%2Fprojects%2Fopencvlibrary%2Ffiles%2Fopencv-unix%2F2.2%2F&ts=1296493923&use_mirror=surfnet
> tar jxvf OpenCV-2.2.0.tar.bz2
> cd OpenCV-2.2.0/
> mkdir build
> cd build/
> cmake ..
> make
> sudo make install

That's it.  It should tell you where it will be installing everything.

This code also requires GLEW, OpenGL dev libraries, Qt, and so on.  I believe all of those are available in the Ubuntu repositories.

HOW TO USE
----------
Nicolas Burrus has put together a nice demo for the Kinect that allows you to view and record pairs of color and IR frames from the Kinect.  He also has a utility that will go in and apply all the helpful OpenCV calib3d functions to compute the intrinsics for both cameras, the extrinsics between the two cameras, and the depth parameters.  There is something funky happening at one point in the depth calibration and I think it's just a conditional that was accidentally deleted, but for the most part the end product is decent.  I'm including a copy of this code in this repository so you know which version I'm talking about or you can go directly to his site: http://nicolas.burrus.name/index.php/Research/KinectRgbDemoV3 Note, it's fairly easy for the OpenCV routines to properly detect the pattern in the IR image when the projector is covered, but it seems really difficult when it is uncovered.  I haven't had calibration for depth succeed, but the code he provides looks correct (except for that one bit above.)

Anyway, the point of all this is that you use his rgbdemo to capture the frames for calibration and run his calibration utility to get a kinect_calibration.yml file.  Then, you can go back into his demo using that calibration file to capture color and depth.  You don't need to capture IR at this point.  This generates a bunch of pngs and yml files.  My program will take in that same calibration file, a manifest, and an optional flag for automatic processing.

The manifest is formatted in the following way.  If you have files view0000.color.png and view0000.depth.yml, then your manifest would have the line:
view0000
Keep in mind that I didn't read through the rgbdemo code to figure out how the undistortion was applied so I do it again.  Just grab the raw images from the capture process.

There are a few ways to control the program.  If you want to just display the image on the screen one at a time, omit the word 'auto' at the end of the command line.  Then you can use the space bar to advance and the escape key to exit.  If you want to just quickly go through a batch of captures, then include the word 'auto'.

The output of the program will be a bunch of <prefix>.calib.jpg and <prefix>.calib.yml
